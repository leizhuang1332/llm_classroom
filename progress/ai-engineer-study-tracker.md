# AI大模型应用开发高级工程师学习跟踪器

**最后更新：** 2025-12-19

## 领域进度汇总表

| 领域 | 主题总数 | 已涵盖 | 未涵盖 | 掌握程度 |
|------|----------|--------|--------|----------|
| A. 大模型基础原理 | 6 | 1 | 5 | 17% |
| B. 大模型开发工具与框架 | 6 | 1 | 5 | 17% |
| C. 提示工程与上下文设计 | 6 | 1 | 5 | 17% |
| D. 大模型应用架构设计 | 6 | 1 | 5 | 17% |
| E. 大模型应用开发实践 | 6 | 0 | 6 | 0% |
| F. 性能优化与部署 | 5 | 0 | 5 | 0% |
| G. 伦理与安全 | 5 | 0 | 5 | 0% |
| H. 前沿技术与趋势 | 4 | 0 | 4 | 0% |
| **总计** | **44** | **4** | **40** | **9%** |

## 已掌握主题

### A. 大模型基础原理

#### A.6 PPO算法原理与应用
- **掌握日期：** 2025-10-14
- **信心水平：** 中
- **理解的关键点：**
  - PPO（近端策略优化）是OpenAI在2017年提出的一种强化学习算法
  - PPO在大语言模型的人类反馈强化学习(RLHF)中被广泛使用
  - 核心原理：剪切更新、策略梯度、双重网络（策略网络和价值网络）
  - PPO的优势：提供更稳定的训练过程
  - PPO的挑战：在大语言模型微调过程中面临计算开销大、策略更新不够稳定等问题
- **参考资料：** 2025-10-14会话讨论

### B. 大模型开发工具与框架

#### B.8 微调框架与工具（PEFT, Llama Factory, DeepSpeed, LoRA, QLoRA, P-tuning, Prefix Tuning等）
- **掌握日期：** 2025-12-19
- **信心水平：** 中高
- **理解的关键点：**
  - 微调算法的基本概念：在预训练大模型基础上，使用特定任务数据进行参数优化
  - LoRA（Low-Rank Adaptation）：通过增加低秩矩阵旁路实现参数高效微调，训练时固定原模型参数只更新低秩矩阵
  - QLoRA（Quantized LoRA）：结合量化和LoRA技术，减少内存和计算资源，适合资源受限场景
  - P-tuning：通过优化提示来间接影响模型输出，固定模型前馈层参数，仅更新部分embedding参数
  - P-tuning v2改进：将参数量减少到0.1%，结合量化和Gradient Checkpoint进一步降低资源需求
  - 微调方法选择指南：根据资源限制、性能需求、应用场景选择合适的微调方法
  - P-tuning实战应用：环境配置、数据准备、模型加载与配置、训练代码实现、推理应用
  - P-tuning使用场景：快速原型开发（训练速度快、资源需求低、实验成本低）、多任务切换（存储效率高、切换速度快、基础模型共享）
- **参考资料：** 2025-12-19会话讨论

### C. 提示工程与上下文设计

#### C.13 提示词设计原则与模式
- **掌握日期：** 2025-10-14
- **信心水平：** 中高
- **理解的关键点：**
  - 提示词工程的定义：设计和优化输入给大模型的文本提示，以引导模型产生期望输出的过程
  - 提示词工程的重要性：同一个模型，不同的提示方式会产生截然不同的结果
  - 提示词工程的五大核心原则：
    - 明确性原则：清晰、具体地描述任务要求和期望输出格式
    - 上下文原则：提供充分的背景信息和相关上下文
    - 示例原则：通过少样本示例引导模型理解任务模式
    - 角色原则：为模型设定特定角色，使其从特定角度回答问题
    - 思维链原则：引导模型逐步思考，展示推理过程
  - 常用提示词技巧：少样本学习、思维链、角色设定、输出格式控制、约束条件、自我反思
- **参考资料：** 2025-10-14会话讨论

### D. 大模型应用架构设计

#### D.19 RAG架构设计与优化
- **掌握日期：** 2025-10-11
- **信心水平：** 高
- **理解的关键点：**
  - RAG（检索增强生成）的概念和工作原理
  - RAG的核心组件：文档加载器、文本分割器、嵌入生成器、向量数据库、检索器、生成器
  - RAG的优势：解决知识截止问题、提高事实准确性、访问企业私有数据、降低成本
  - RAG与微调的区别及适用场景
  - RAG的优化方法：
    - 检索阶段优化：查询优化、索引优化、检索策略优化
    - 文档处理阶段优化：文本分割优化、嵌入优化
    - 生成阶段优化：上下文优化、提示工程优化
    - 系统级优化：缓存策略、并行处理、硬件优化
  - 向量索引算法：
    - 向量索引的基本概念和作用
    - 常见向量索引算法类型（树类、图类、量化、混合）
    - 重点算法：IVF（倒排文件索引）和HNSW（分层可导航小世界）的工作原理
    - 不同向量索引算法的优缺点和适用场景
- **参考资料：** 2025-10-11、2025-10-12、2025-10-13会话讨论

## 知识缺口

### 高优先级
- 对提示词工程的实践应用缺乏经验
- 对PPO算法在大模型训练中的具体实现细节了解不足
- 缺乏RAG架构的实际项目经验
- 对其他微调算法（如Prefix Tuning、Adapter）的详细实现了解不足

### 中优先级
- 对重排序模型的实现细节缺乏深入理解
- 对向量量化技术（如PQ）的工作原理了解不足
- 缺乏实际构建和调优向量索引的经验
- 对大模型微调的超参数调优策略了解不足

### 低优先级
- 无

## 最近解决的知识缺口
- **对提示词工程的基本概念和原则缺乏了解**：于2025-10-14解决，已学习提示词工程的定义、重要性、五大核心原则和常用技巧
- **对PPO算法的基本概念缺乏了解**：于2025-10-14解决，已学习PPO算法的基本概念、核心原理、在大模型训练中的应用以及优势与挑战
- **对具体向量索引算法（如HNSW、IVF）的工作原理了解不足**：于2025-10-13解决，已深入学习向量索引算法的概念、原理和常见类型，特别是IVF和HNSW算法的工作原理和应用场景
- **对微调算法的基本概念和实现缺乏了解**：于2025-12-19解决，已学习LoRA、QLoRA、P-tuning等微调算法的原理、实现和应用场景，特别是P-tuning的实战应用和场景选择

## 学习计划

### 短期目标（1-2周）
1. 深入学习提示词工程的实践应用
2. 继续学习大模型开发工具与框架的其他主题
3. 实践P-tuning微调方法，完成一个小型项目
4. 学习其他微调算法（Prefix Tuning、Adapter等）

### 中期目标（3-4周）
1. 掌握大模型应用架构设计的其他主题
2. 实践RAG应用开发
3. 学习性能优化与部署基础知识
4. 完成一个包含微调和RAG的综合项目

### 长期目标（1-2个月）
1. 全面掌握所有核心知识领域
2. 完成多个AI大模型应用开发项目
3. 准备AI大模型应用开发高级工程师认证

## 快速统计

- **总体进度：** 9%
- **已掌握主题数：** 4
- **知识缺口数：** 8
- **最近学习日期：** 2025-12-19